# RAGé‡æ’åºç³»ç»ŸæŠ€æœ¯æ–‡æ¡£

## æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†æè¿°äº†RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ç³»ç»Ÿçš„é‡æ’åºæ¨¡å—å®ç°ã€‚è¯¥ç³»ç»Ÿé€šè¿‡å¤šé˜¶æ®µé‡æ’åºç®—æ³•ä¼˜åŒ–æ£€ç´¢ç»“æœï¼Œç»“åˆå…³é”®è¯åŒ¹é…ã€é•¿åº¦é€‚åº”å’Œå¯¹æ¯”å­¦ä¹ æŠ€æœ¯ï¼Œæ˜¾è‘—æå‡æœ€ç»ˆç­”æ¡ˆçš„ç›¸å…³æ€§å’Œå‡†ç¡®æ€§ã€‚

## ç³»ç»Ÿæ¶æ„

### 1. æ ¸å¿ƒç»„ä»¶

#### 1.1 é‡æ’åºå™¨ç±»å‹

| é‡æ’åºå™¨ç±»å‹ | æŠ€æœ¯æ–¹æ¡ˆ | ä¸»è¦åŠŸèƒ½ | é€‚ç”¨åœºæ™¯ |
|-------------|----------|----------|----------|
| `SimpleReranker` | å…³é”®è¯+é•¿åº¦å¯å‘å¼ | åŸºç¡€é‡æ’åº | é€šç”¨åœºæ™¯ |
| `ContrastiveReranker` | å¯¹æ¯”å­¦ä¹ å¢å¼º | è´Ÿæ ·æœ¬æŠ‘åˆ¶ | è®­ç»ƒæ•°æ®å……è¶³åœºæ™¯ |

#### 1.2 åŠŸèƒ½å®šä½

- **ä¼˜åŒ–ç›®æ ‡**: æå‡æ£€ç´¢ç»“æœçš„ç›¸å…³æ€§å’Œå‡†ç¡®æ€§
- **æŠ€æœ¯è·¯çº¿**: å¤šç»´åº¦ç‰¹å¾èåˆ + æœºå™¨å­¦ä¹ å¢å¼º
- **è®¾è®¡åŸåˆ™**: è½»é‡çº§ã€å¯è§£é‡Šã€æ˜“æ‰©å±•
- **æ€§èƒ½è¦æ±‚**: ä½å»¶è¿Ÿã€é«˜å‡†ç¡®ç‡

### 2. SimpleReranker åŸºç¡€é‡æ’åºå™¨

#### 2.1 åˆå§‹åŒ–é…ç½®

```python
SimpleReranker(
    keyword_weight=0.7,   # å…³é”®è¯åŒ¹é…æƒé‡ (0.0-1.0)
    length_weight=0.3     # é•¿åº¦é€‚åº”æƒé‡ (0.0-1.0)
)
```

#### 2.2 è¯„åˆ†ç®—æ³•

**ç»¼åˆè¯„åˆ†å…¬å¼**
```
FinalScore = keyword_weight Ã— KeywordScore + length_weight Ã— LengthScore
```

**å…³é”®è¯è¯„åˆ†ç®—æ³•**
```python
def _calculate_keyword_score(self, query_keywords, doc_text):
    matches = 0
    for keyword in query_keywords:
        if exact_match(keyword, doc_text):
            matches += 1.0      # ç²¾ç¡®åŒ¹é…
        elif partial_match(keyword, doc_text):
            matches += 0.5      # éƒ¨åˆ†åŒ¹é…
    return matches / len(query_keywords)
```

**é•¿åº¦è¯„åˆ†ç®—æ³•**
```python
def _calculate_length_score(self, query, doc_text):
    # åŸºäºæŸ¥è¯¢é•¿åº¦ç¡®å®šç†æƒ³æ–‡æ¡£é•¿åº¦
    query_length = len(query.split())
    if query_length <= 3: ideal = 150
    elif query_length <= 8: ideal = 300
    else: ideal = 500
    
    # è®¡ç®—é•¿åº¦é€‚åº”åº¦
    length_diff = abs(len(doc_text) - ideal)
    return max(0, 1 - (length_diff / ideal))
```

#### 2.3 å…³é”®è¯æå–

**åœç”¨è¯è¿‡æ»¤**
```python
STOPWORDS = {
    'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',
    'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'have',
    'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should',
    'what', 'where', 'when', 'why', 'how', 'who', 'which', 'that', 'this'
}
```

**å…³é”®è¯æå–æµç¨‹**
```
è¾“å…¥æ–‡æœ¬ â†’ å°å†™è½¬æ¢ â†’ æ­£åˆ™åˆ†è¯ â†’ åœç”¨è¯è¿‡æ»¤ â†’ çŸ­è¯è¿‡æ»¤ â†’ å…³é”®è¯åˆ—è¡¨
```

### 3. ContrastiveReranker å¯¹æ¯”å­¦ä¹ é‡æ’åºå™¨

#### 3.1 è®¾è®¡åŸç†

**è´Ÿæ ·æœ¬æŠ‘åˆ¶æœºåˆ¶**
- **è¯†åˆ«è´Ÿæ ·æœ¬**: åŸºäºæ–‡æœ¬ç›¸ä¼¼åº¦æ£€æµ‹
- **åˆ†æ•°æƒ©ç½š**: è´Ÿæ ·æœ¬åˆ†æ•°ä¹˜ä»¥0.3å€
- **æ­£æ ·æœ¬æå‡**: éè´Ÿæ ·æœ¬åˆ†æ•°ä¹˜ä»¥1.1å€

#### 3.2 ç›¸ä¼¼åº¦è®¡ç®—

**æ–‡æœ¬ç›¸ä¼¼åº¦ç®—æ³•**
```python
def _text_similarity(self, text1, text2):
    words1 = set(text1.split())
    words2 = set(text2.split())
    intersection = len(words1.intersection(words2))
    union = len(words1.union(words2))
    return intersection / union if union > 0 else 0.0
```

**è´Ÿæ ·æœ¬æ£€æµ‹**
```python
def _is_similar_to_negatives(self, doc_text, negative_samples):
    doc_clean = normalize_text(doc_text)
    for neg in negative_samples:
        neg_text = normalize_text(neg['text'])
        if similarity(doc_clean, neg_text) > 0.7:
            return True
    return False
```

### 4. é‡æ’åºå±•ç¤ºç³»ç»Ÿ

#### 4.1 ä¸»å‡½æ•°ï¼š`show_retrieved_documents_with_rerank()`

**åŠŸèƒ½æµç¨‹**
```
æ£€ç´¢æ–‡æ¡£ â†’ é‡æ’åºå¤„ç† â†’ ç±»å‹æ ‡æ³¨ â†’ ç»“æœå±•ç¤º â†’ ç»Ÿè®¡åˆ†æ
```

**å‚æ•°è¯´æ˜**
| å‚æ•°å | ç±»å‹ | æè¿° | å¿…éœ€ |
|--------|------|------|------|
| `db` | VectorStore | å‘é‡æ•°æ®åº“å®ä¾‹ | æ˜¯ |
| `question` | str | æŸ¥è¯¢é—®é¢˜ | æ˜¯ |
| `contrastive_data` | dict | å¯¹æ¯”å­¦ä¹ æ•°æ® | å¦ |
| `reranker` | Reranker | é‡æ’åºå™¨å®ä¾‹ | å¦ |

#### 4.2 ç»“æœå±•ç¤ºæ ¼å¼

**æ ‡å‡†è¾“å‡ºæ ¼å¼**
```
[é‡æ’åºæ–‡æ¡£ 1] ğŸŸ¢ æ­£æ ·æœ¬ | åˆ†æ•°: 0.892
   ä»ç¬¬3ä½ä¸Šå‡åˆ°ç¬¬1ä½
   åŸå› : å…³é”®è¯åŒ¹é…åº¦é«˜; é•¿åº¦é€‚ä¸­
   å†…å®¹: Machine learning is a subset of artificial intelligence...
```

**è´¨é‡åˆ†ææŠ¥å‘Š**
```
æ£€ç´¢è´¨é‡åˆ†æ:
    æ­£æ ·æœ¬æ–‡æ¡£: 4/5 (80.0%)
    è´Ÿæ ·æœ¬æ–‡æ¡£: 1/5 (20.0%)
    æ£€ç´¢è´¨é‡: ä¼˜ç§€ (80.0åˆ†)
    é‡æ’åºåè´¨é‡: 92.0åˆ†
    é‡æ’åºæ”¹è¿›: +12.0åˆ† (æ˜¾è‘—æå‡)
```

### 5. ä½¿ç”¨ç¤ºä¾‹

#### 5.1 åŸºç¡€ä½¿ç”¨

```python
from reranking import SimpleReranker, ContrastiveReranker, create_reranker

# åˆ›å»ºé‡æ’åºå™¨
simple_reranker = SimpleReranker(keyword_weight=0.8, length_weight=0.2)
contrastive_reranker = ContrastiveReranker()

# ä½¿ç”¨å·¥å‚å‡½æ•°åˆ›å»º
reranker = create_reranker("simple", keyword_weight=0.7, length_weight=0.3)
```

#### 5.2 å®Œæ•´ç¤ºä¾‹

```python
from reranking import show_retrieved_documents_with_rerank

# å‡†å¤‡æ•°æ®
question = "What is machine learning?"
contrastive_data = {
    'positive_samples': [...],
    'negative_samples': [...],
    'triplets': [...]
}

# åº”ç”¨é‡æ’åº
final_docs = show_retrieved_documents_with_rerank(
    db=vector_db,
    question=question,
    contrastive_data=contrastive_data,
    reranker=simple_reranker
)
```

#### 5.3 æ‰¹é‡æ¼”ç¤º

```python
def demo_reranking_pipeline():
    """å®Œæ•´çš„é‡æ’åºæ¼”ç¤ºæµç¨‹"""
    
    demo_questions = [
        "What is machine learning?",
        "How does AI work?",
        "What are neural networks?"
    ]
    
    for question in demo_questions:
        print(f"\n{'='*60}")
        print(f"æ¼”ç¤ºé—®é¢˜: {question}")
        print('='*60)
        
        # åŸå§‹æ£€ç´¢
        retriever = vector_db.as_retriever(search_kwargs={"k": 5})
        docs = retriever.get_relevant_documents(question)
        
        print("\nåŸå§‹æ£€ç´¢ç»“æœ:")
        for i, doc in enumerate(docs[:3], 1):
            print(f"  [{i}] {doc.page_content[:100]}...")
        
        # é‡æ’åºå
        reranked = simple_reranker.rerank_documents(question, docs, top_k=3)
        print("\né‡æ’åºåç»“æœ:")
        for i, (doc, score) in enumerate(reranked, 1):
            print(f"  [{i}] åˆ†æ•°: {score:.3f} | {doc.page_content[:100]}...")
```

### 6. æ€§èƒ½ä¼˜åŒ–

#### 6.1 è®¡ç®—ä¼˜åŒ–

**ç¼“å­˜æœºåˆ¶**
```python
from functools import lru_cache

class CachedReranker(SimpleReranker):
    @lru_cache(maxsize=1000)
    def _extract_keywords(self, text):
        return super()._extract_keywords(text)
```

**æ‰¹å¤„ç†ä¼˜åŒ–**
```python
def batch_rerank(self, queries, documents_list):
    """æ‰¹é‡é‡æ’åº"""
    return [self.rerank_documents(q, docs) for q, docs in zip(queries, documents_list)]
```

#### 6.2 ç®—æ³•è°ƒä¼˜

**åŠ¨æ€æƒé‡è°ƒæ•´**
```python
def adaptive_weights(query_length, doc_count):
    """æ ¹æ®æŸ¥è¯¢å’Œæ–‡æ¡£æ•°é‡åŠ¨æ€è°ƒæ•´æƒé‡"""
    if query_length < 5:
        return 0.8, 0.2  # çŸ­æŸ¥è¯¢æ›´é‡å…³é”®è¯
    else:
        return 0.6, 0.4  # é•¿æŸ¥è¯¢å¹³è¡¡è€ƒè™‘
```

### 7. è´¨é‡åˆ†æ

#### 7.1 æ£€ç´¢è´¨é‡è¯„ä¼°

**è´¨é‡åˆ†æ•°è®¡ç®—**
```python
def analyze_quality(retrieved_docs, contrastive_data):
    positive = count_positive_docs(retrieved_docs, contrastive_data)
    total = len(retrieved_docs)
    
    quality_score = (positive / total) * 100
    
    if quality_score >= 80:
        level = "ä¼˜ç§€"
    elif quality_score >= 60:
        level = "è‰¯å¥½"
    else:
        level = "éœ€è¦æ”¹è¿›"
    
    return {"score": quality_score, "level": level}
```

#### 7.2 é‡æ’åºæ•ˆæœåˆ†æ

**æ”¹è¿›åº¦é‡**
```python
def measure_rerank_improvement(original, reranked, contrastive_data):
    original_quality = analyze_quality(original, contrastive_data)
    reranked_quality = analyze_quality(reranked, contrastive_data)
    
    improvement = reranked_quality['score'] - original_quality['score']
    
    return {
        "original_score": original_quality['score'],
        "reranked_score": reranked_quality['score'],
        "improvement": improvement,
        "significance": "æ˜¾è‘—æå‡" if improvement > 10 else "è½»å¾®æå‡"
    }
```

### 8. æ‰©å±•åŠŸèƒ½

#### 8.1 è‡ªå®šä¹‰é‡æ’åºå™¨

**æ‰©å±•åŸºç±»**
```python
class CustomReranker(SimpleReranker):
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.custom_weight = kwargs.get('custom_weight', 0.5)
    
    def _calculate_custom_score(self, query, doc_text):
        """æ·»åŠ è‡ªå®šä¹‰è¯„åˆ†ç»´åº¦"""
        # å®ç°è‡ªå®šä¹‰è¯„åˆ†é€»è¾‘
        return 0.0
    
    def rerank_documents(self, query, documents, top_k=5):
        base_results = super().rerank_documents(query, documents, len(documents))
        
        # æ·»åŠ è‡ªå®šä¹‰è¯„åˆ†
        enhanced_results = []
        for doc, base_score in base_results:
            custom_score = self._calculate_custom_score(query, doc.page_content)
            final_score = base_score * (1 - self.custom_weight) + custom_score * self.custom_weight
            enhanced_results.append((doc, final_score))
        
        enhanced_results.sort(key=lambda x: x[1], reverse=True)
        return enhanced_results[:top_k]
```

#### 8.2 æœºå™¨å­¦ä¹ å¢å¼º

**é›†æˆé¢„è®­ç»ƒæ¨¡å‹**
```python
class MLLMReranker:
    def __init__(self, model_name="cross-encoder"):
        self.model = load_cross_encoder(model_name)
    
    def rerank_documents(self, query, documents, top_k=5):
        scores = []
        for doc in documents:
            score = self.model.predict([(query, doc.page_content)])[0]
            scores.append((doc, score))
        
        scores.sort(key=lambda x: x[1], reverse=True)
        return scores[:top_k]
```

### 9. ç›‘æ§ä¸è°ƒè¯•

#### 9.1 è°ƒè¯•å·¥å…·

**è¯¦ç»†æ—¥å¿—**
```python
import logging

class DebugReranker(SimpleReranker):
    def rerank_documents(self, query, documents, top_k=5):
        logger.debug(f"Query: {query}")
        logger.debug(f"Documents count: {len(documents)}")
        
        query_keywords = self._extract_keywords(query.lower())
        logger.debug(f"Keywords: {query_keywords}")
        
        results = super().rerank_documents(query, documents, top_k)
        
        for doc, score in results:
            logger.debug(f"Score: {score:.3f}, Doc: {doc.page_content[:100]}...")
        
        return results
```

#### 9.2 æ€§èƒ½ç›‘æ§

**æŒ‡æ ‡æ”¶é›†**
```python
class MonitoredReranker:
    def __init__(self, base_reranker):
        self.base_reranker = base_reranker
        self.metrics = {
            'total_queries': 0,
            'total_documents': 0,
            'avg_processing_time': 0.0
        }
    
    def rerank_documents(self, query, documents, top_k=5):
        start_time = time.time()
        
        result = self.base_reranker.rerank_documents(query, documents, top_k)
        
        self.metrics['total_queries'] += 1
        self.metrics['total_documents'] += len(documents)
        processing_time = time.time() - start_time
        
        # æ›´æ–°å¹³å‡å¤„ç†æ—¶é—´
        total_time = self.metrics['avg_processing_time'] * (self.metrics['total_queries'] - 1)
        self.metrics['avg_processing_time'] = (total_time + processing_time) / self.metrics['total_queries']
        
        return result
```

### 10. éƒ¨ç½²å»ºè®®

#### 10.1 ç”Ÿäº§é…ç½®

**æ¨èå‚æ•°**
```python
# ç”Ÿäº§ç¯å¢ƒé…ç½®
production_reranker = SimpleReranker(
    keyword_weight=0.75,
    length_weight=0.25
)

# é«˜è´Ÿè½½ä¼˜åŒ–
high_performance_reranker = CachedReranker(
    keyword_weight=0.7,
    length_weight=0.3
)
```

#### 10.2 A/Bæµ‹è¯•æ¡†æ¶

```python
def ab_test_rerankers(query, documents, rerankers):
    """A/Bæµ‹è¯•å¤šä¸ªé‡æ’åºå™¨"""
    results = {}
    for name, reranker in rerankers.items():
        start_time = time.time()
        reranked = reranker.rerank_documents(query, documents, top_k=5)
        processing_time = time.time() - start_time
        
        results[name] = {
            'results': reranked,
            'processing_time': processing_time,
            'top_score': reranked[0][1] if reranked else 0
        }
    
    return results
```

## æ€»ç»“

æœ¬é‡æ’åºç³»ç»Ÿæä¾›äº†å®Œæ•´çš„RAGæ£€ç´¢ä¼˜åŒ–è§£å†³æ–¹æ¡ˆï¼Œé€šè¿‡å¤šå±‚æ¬¡ã€å¤šç»´åº¦çš„é‡æ’åºç®—æ³•æ˜¾è‘—æå‡æ£€ç´¢è´¨é‡ã€‚ç³»ç»Ÿè®¾è®¡å…¼é¡¾äº†æ€§èƒ½ã€å‡†ç¡®æ€§å’Œæ‰©å±•æ€§ï¼Œæ”¯æŒä»ç®€å•çš„å¯å‘å¼æ–¹æ³•åˆ°å¤æ‚çš„æœºå™¨å­¦ä¹ å¢å¼ºï¼Œé€‚ç”¨äºä¸åŒè§„æ¨¡å’Œéœ€æ±‚çš„åº”ç”¨åœºæ™¯ã€‚é€šè¿‡çµæ´»çš„é…ç½®å’Œä¸°å¯Œçš„è°ƒè¯•å·¥å…·ï¼Œå¼€å‘è€…å¯ä»¥å¿«é€Ÿé›†æˆå¹¶ä¼˜åŒ–å…¶RAGç³»ç»Ÿçš„æ£€ç´¢æ•ˆæœã€‚